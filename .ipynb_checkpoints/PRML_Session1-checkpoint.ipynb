{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f65107",
   "metadata": {},
   "source": [
    "# セッション1: モデル選択と情報理論\n",
    "PRML 第1章より、モデルの複雑さ、情報理論、次元の呪いに関する演習です。\n",
    "\n",
    "## 目的\n",
    "- 過学習と汎化誤差の違いを理解する\n",
    "- 次元の呪いの影響を可視化する\n",
    "- 情報理論の基礎（KLダイバージェンス）を実装で確認する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f744133",
   "metadata": {},
   "source": [
    "## 問題1: モデルの複雑さと過学習\n",
    "多項式回帰を使って、モデルの複雑さ（次数）によって訓練誤差とテスト誤差がどのように変化するかを調べましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b30c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "N = 30\n",
    "x = np.linspace(0, 1, N)\n",
    "t_true = np.sin(2 * np.pi * x)\n",
    "noise_sigma = 0.2\n",
    "t = t_true + np.random.normal(0, noise_sigma, size=N)\n",
    "\n",
    "# データ分割\n",
    "N_train = int(0.7 * N)\n",
    "x_train, x_test = x[:N_train], x[N_train:]\n",
    "t_train, t_test = t[:N_train], t[N_train:]\n",
    "\n",
    "max_degree = 9\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for M in range(0, max_degree + 1):\n",
    "    Phi_train = np.vstack([x_train ** j for j in range(M + 1)]).T\n",
    "    Phi_test = np.vstack([x_test ** j for j in range(M + 1)]).T\n",
    "    w, *_ = np.linalg.lstsq(Phi_train, t_train, rcond=None)\n",
    "    train_pred = Phi_train.dot(w)\n",
    "    train_mse = np.mean((train_pred - t_train) ** 2)\n",
    "    train_errors.append(train_mse)\n",
    "    test_pred = Phi_test.dot(w)\n",
    "    test_mse = np.mean((test_pred - t_test) ** 2)\n",
    "    test_errors.append(test_mse)\n",
    "\n",
    "# TODO: 以下のコードを使ってプロットし、過学習の例を確認しましょう。\n",
    "plt.plot(____, train_errors, marker='o', label=\"訓練誤差\")\n",
    "plt.plot(____, test_errors, marker='o', label=\"テスト誤差\")\n",
    "plt.xlabel(\"多項式の次数 M\")\n",
    "plt.ylabel(\"平均二乗誤差 (MSE)\")\n",
    "plt.title(\"モデルの複雑さと誤差\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9685b7b0",
   "metadata": {},
   "source": [
    "## 問題2: 次元の呪い\n",
    "高次元空間における「最近傍点と最遠点の距離比」を計算し、次元が上がるとどうなるかを確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45855b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [1, 2, 5, 10, 50, 100]\n",
    "num_points = 1000\n",
    "\n",
    "for d in dims:\n",
    "    data = np.random.rand(num_points, d)\n",
    "    query = np.random.rand(1, d)\n",
    "    distances = np.linalg.norm(data - query, axis=1)\n",
    "    nearest = distances.min()\n",
    "    farthest = distances.max()\n",
    "    ratio = ____ / ____\n",
    "    print(f\"{d}次元: 最近傍距離={nearest:.4f}, 最遠距離={farthest:.4f}, 比率={ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433bf0db",
   "metadata": {},
   "source": [
    "## 問題3: KLダイバージェンス\n",
    "2つの離散確率分布間のKLダイバージェンスを計算してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea28c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([0.8, 0.2])\n",
    "Q = np.array([0.5, 0.5])\n",
    "\n",
    "KL_PQ = np.sum(P * np.log(P / Q))\n",
    "KL_QP = np.sum(Q * np.log(Q / P))\n",
    "\n",
    "# TODO: 結果を出力して非対称性を確認しましょう\n",
    "print(\"KL(P||Q) =\", ____)\n",
    "print(\"KL(Q||P) =\", ____)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
